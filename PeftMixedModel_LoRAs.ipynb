{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "注意，PeftModel只支持相同adapter的模型，而PeftMixedModel支持不同adapter的模型。\n",
    "\n",
    "PeftModel一次只能激活一个adapter，而PeftMixedModel可以激活多个adapter。"
   ],
   "id": "1209f932b289349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:32:48.790293Z",
     "start_time": "2024-12-06T11:32:47.218346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from peft.tuners import MixedModel\n",
    "\n",
    "base_model = 'Qwen/Qwen2-7B-Instruct'  # load the base model, e.g. from transformers"
   ],
   "id": "2f414a6204d5415e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:05.884339Z",
     "start_time": "2024-12-06T11:32:48.796093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load base model\n",
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(base_model)"
   ],
   "id": "71770cc555aca490",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34f28e258c1a46369b5071774b55bdd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:06.072055Z",
     "start_time": "2024-12-06T11:33:05.982646Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load the model with PEFT\n",
    "from peft import PeftMixedModel, LoraConfig\n",
    "\n",
    "rank = 4\n",
    "LoRA_amount = 3\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    inference_mode=False,\n",
    "    r=rank,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1\n",
    ")\n",
    "model = PeftMixedModel(model, peft_config, adapter_name=\"0\")\n",
    "for LoRA_index in range(1, LoRA_amount):\n",
    "    model.add_adapter(str(LoRA_index), peft_config)"
   ],
   "id": "c974f33c336d8da4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/memo/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:06.143455Z",
     "start_time": "2024-12-06T11:33:06.137935Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "18caf537b3b5a5a1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftMixedModel(\n",
       "  (base_model): MixedModel(\n",
       "    (model): Qwen2Model(\n",
       "      (embed_tokens): Embedding(152064, 3584)\n",
       "      (layers): ModuleList(\n",
       "        (0-27): 28 x Qwen2DecoderLayer(\n",
       "          (self_attn): Qwen2SdpaAttention(\n",
       "            (q_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (0): Dropout(p=0.1, inplace=False)\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "                (2): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (0): Linear(in_features=3584, out_features=4, bias=False)\n",
       "                (1): Linear(in_features=3584, out_features=4, bias=False)\n",
       "                (2): Linear(in_features=3584, out_features=4, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (0): Linear(in_features=4, out_features=3584, bias=False)\n",
       "                (1): Linear(in_features=4, out_features=3584, bias=False)\n",
       "                (2): Linear(in_features=4, out_features=3584, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "            (v_proj): lora.Linear(\n",
       "              (base_layer): Linear(in_features=3584, out_features=512, bias=True)\n",
       "              (lora_dropout): ModuleDict(\n",
       "                (0): Dropout(p=0.1, inplace=False)\n",
       "                (1): Dropout(p=0.1, inplace=False)\n",
       "                (2): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (lora_A): ModuleDict(\n",
       "                (0): Linear(in_features=3584, out_features=4, bias=False)\n",
       "                (1): Linear(in_features=3584, out_features=4, bias=False)\n",
       "                (2): Linear(in_features=3584, out_features=4, bias=False)\n",
       "              )\n",
       "              (lora_B): ModuleDict(\n",
       "                (0): Linear(in_features=4, out_features=512, bias=False)\n",
       "                (1): Linear(in_features=4, out_features=512, bias=False)\n",
       "                (2): Linear(in_features=4, out_features=512, bias=False)\n",
       "              )\n",
       "              (lora_embedding_A): ParameterDict()\n",
       "              (lora_embedding_B): ParameterDict()\n",
       "              (lora_magnitude_vector): ModuleDict()\n",
       "            )\n",
       "            (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "            (rotary_emb): Qwen2RotaryEmbedding()\n",
       "          )\n",
       "          (mlp): Qwen2MLP(\n",
       "            (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "            (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "          (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "          (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        )\n",
       "      )\n",
       "      (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:06.227452Z",
     "start_time": "2024-12-06T11:33:06.222443Z"
    }
   },
   "cell_type": "code",
   "source": "model.set_adapter(['0', '1', '2'])",
   "id": "4a2643a70e5e2c42",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:06.243052Z",
     "start_time": "2024-12-06T11:33:06.240753Z"
    }
   },
   "cell_type": "code",
   "source": "model.active_adapters",
   "id": "2e102622341ea47c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:33:51.401272Z",
     "start_time": "2024-12-06T11:33:06.282014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 保存adapter的参数\n",
    "save_dir = \"output/lora/\"\n",
    "model.save_pretrained(save_directory=save_dir, selected_adapters='0')\n",
    "model.save_pretrained(save_directory=save_dir, selected_adapters='1')\n",
    "model.save_pretrained(save_directory=save_dir, selected_adapters='2')"
   ],
   "id": "21868f1f49e4493f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/memo/lib/python3.10/site-packages/peft/mixed_model.py:447: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  ptr = (id(tensor.storage()), tensor.storage_offset(), tensor.size())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapters 0 saved to output/lora/\n",
      "Adapters 1 saved to output/lora/\n",
      "Adapters 2 saved to output/lora/\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:59:16.269588Z",
     "start_time": "2024-12-06T11:58:45.468551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "from peft import PeftConfig, PeftMixedModel\n",
    "from safetensors import safe_open\n",
    "\n",
    "# 基础模型\n",
    "base_model_name = \"Qwen/Qwen2-7B-Instruct\"\n",
    "base_model = AutoModel.from_pretrained(base_model_name, torch_dtype=torch.float16)\n",
    "\n",
    "# 假设你的adapter目录如下：\n",
    "# output/lora/0/\n",
    "#   adapter_config.json\n",
    "#   adapter_model.safetensors\n",
    "# output/lora/1/\n",
    "#   adapter_config.json\n",
    "#   adapter_model.safetensors\n",
    "# output/lora/2/\n",
    "#   adapter_config.json\n",
    "#   adapter_model.safetensors\n",
    "\n",
    "# 初始要加载0号adapter\n",
    "adapter_dir_0 = \"output/lora/0\"\n",
    "adapter_name_to_load = \"0\"\n",
    "\n",
    "# 后续要添加1和2号adapter\n",
    "adapter_dir_others = [\"output/lora/1\", \"output/lora/2\"]\n",
    "adapter_names_to_add = [\"1\", \"2\"]\n",
    "\n",
    "# 1. 加载0号adapter的配置\n",
    "adapter_config_0 = PeftConfig.from_pretrained(adapter_dir_0)\n",
    "\n",
    "# 2. 使用0号adapter配置构建PeftMixedModel\n",
    "mixed_model = PeftMixedModel(base_model, adapter_config_0, adapter_name=adapter_name_to_load)\n",
    "\n",
    "# 3. 加载0号adapter的权重\n",
    "adapter_weights_path_0 = f\"{adapter_dir_0}/adapter_model.safetensors\"\n",
    "adapter_state_dict_0 = {}\n",
    "with safe_open(adapter_weights_path_0, framework=\"pt\", device=\"cpu\") as f:\n",
    "    for key in f.keys():\n",
    "        adapter_state_dict_0[key] = f.get_tensor(key)\n",
    "\n",
    "mixed_model.load_state_dict(adapter_state_dict_0, strict=False)\n",
    "mixed_model.set_adapter(adapter_name_to_load)\n",
    "\n",
    "print(f\"Adapter {adapter_name_to_load} loaded successfully.\")\n",
    "\n",
    "# 4. 依次添加并加载其他adapter (1号和2号)\n",
    "for adapter_path, adapter_name in zip(adapter_dir_others, adapter_names_to_add):\n",
    "    # 加载adapter配置\n",
    "    adapter_config_i = PeftConfig.from_pretrained(adapter_path)\n",
    "    # 添加adapter结构\n",
    "    mixed_model.add_adapter(adapter_name, adapter_config_i)\n",
    "    # 加载该adapter的权重\n",
    "    adapter_weights_path_i = f\"{adapter_path}/adapter_model.safetensors\"\n",
    "    adapter_state_dict_i = {}\n",
    "    with safe_open(adapter_weights_path_i, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            adapter_state_dict_i[key] = f.get_tensor(key)\n",
    "    mixed_model.load_state_dict(adapter_state_dict_i, strict=False)\n",
    "    print(f\"Adapter {adapter_name} loaded successfully.\")\n",
    "\n",
    "# 5. 设置所有adapter为active\n",
    "mixed_model.set_adapter([adapter_name_to_load] + adapter_names_to_add)\n",
    "print(\"All adapters are set and ready to use.\")\n"
   ],
   "id": "cf622c4413f0518e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe14161c021d4c7e960a89508d4a6deb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adapter 0 loaded successfully.\n",
      "Adapter 1 loaded successfully.\n",
      "Adapter 2 loaded successfully.\n",
      "All adapters are set and ready to use.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:59:28.473169Z",
     "start_time": "2024-12-06T11:59:28.466155Z"
    }
   },
   "cell_type": "code",
   "source": "mixed_model.set_adapter(['0', '1', '2'])",
   "id": "53e573fc3f503455",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T11:59:31.051426Z",
     "start_time": "2024-12-06T11:59:31.047595Z"
    }
   },
   "cell_type": "code",
   "source": "mixed_model.active_adapters",
   "id": "42c817634a7edff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f80ed3ef90b2eb60"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
